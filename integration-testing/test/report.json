{"data": [{"type": "report", "id": 1, "attributes": {"environment": {"Python": "3.6.7", "Platform": "Linux-4.18.0-18-generic-x86_64-with-Ubuntu-18.04-bionic"}, "summary": {"failed": 3, "num_tests": 3, "duration": 73.46209812164307}, "created_at": "2019-05-19 12:31:15.541611"}, "relationships": {"tests": {"data": [{"id": 1, "type": "test"}, {"id": 2, "type": "test"}, {"id": 3, "type": "test"}]}}}], "included": [{"id": 1, "type": "test", "attributes": {"name": "test/test_network_topology.py::test_metrics_api_socket", "duration": 33.851473569869995, "run_index": 0, "setup": {"name": "setup", "duration": 0.009525299072265625, "outcome": "passed"}, "call": {"name": "call", "duration": 33.83219575881958, "outcome": "failed", "longrepr": "command_line_options_fixture = CommandLineOptions(peer_count=2, node_startup_timeout=180, network_converge_timeout=220, receive_timeout=30, command_timeout=10, blocks=1, mount_dir=None)\ndocker_client_fixture = <docker.client.DockerClient object at 0x7f6a9a2a34e0>\n\n    def test_metrics_api_socket(command_line_options_fixture, docker_client_fixture):\n        with conftest.testing_context(command_line_options_fixture, docker_client_fixture) as context:\n>           with complete_network(context) as network:\n\ntest_network_topology.py:33: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/lib/python3.6/contextlib.py:81: in __enter__\n    return next(self.gen)\ncl_node/casperlabsnode.py:787: in complete_network\n    wait_for_started_network(context.node_startup_timeout, network)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nnode_startup_timeout = 180, network = <test.cl_node.common.Network object at 0x7f6a9a2b53c8>\n\n    def wait_for_started_network(node_startup_timeout: int, network: 'Network'):\n>       for peer in network.cl_nodes:\nE       AttributeError: 'Network' object has no attribute 'cl_nodes'\n\ncl_node/wait.py:344: AttributeError", "log": "INFO     root:casperlabsnode.py:303 bootstrap.casperlabsfpuel command: run -s --server-host bootstrap.casperlabsfpuel --tls-certificate /root/.casperlabs/bootstrap/node.certificate.pem --tls-key /root/.casperlabs/bootstrap/node.key.pem --casper-validator-private-key 901b1f0837b7e891d7c2ea0047f502fd95637e450b0226c39a97d68dd951c8a7 --casper-validator-public-key 00322ba649cebf90d8bd0eeb0658ea7957bcc59ecee0676c86f4fec517c06251 --grpc-socket /root/.casperlabs/sockets/.casper-node.sock --metrics-prometheus \nINFO     root:wait.py:206 AWAITING <NodeStarted('bootstrap.casperlabsfpuel', 'io.casperlabs.node.NodeRuntime - Listening for traffic on casperlabs')>\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabsfpuel: 10:30:06.309 [main] INFO  io.casperlabs.node.Main$ - CasperLabs node 0.3 (176160cd54206e3f9d599604b5e7a5e80e98f354)\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabsfpuel: 10:30:06.315 [main] INFO  io.casperlabs.node.NodeEnvironment$ - Using data dir: /root/.casperlabs\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabsfpuel: 10:30:06.534 [main] INFO  io.casperlabs.comm.UPnP$ - trying to open ports using UPnP....\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabsfpuel: 10:30:15.580 [main] INFO  io.casperlabs.comm.UPnP$ - INFO - No gateway devices found\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabsfpuel: 10:30:15.580 [main] INFO  io.casperlabs.comm.UPnP$ - No need to open any port\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabsfpuel: 10:30:16.078 [main] WARN  i.c.b.BlockDagFileStorage$ - CRC file /root/.casperlabs/dagstorage/latest-messages-crc did not contain a valid CRC value\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabsfpuel: 10:30:16.109 [main] WARN  i.c.b.BlockDagFileStorage$ - CRC file /root/.casperlabs/dagstorage/block-metadata-crc did not contain a valid CRC value\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabsfpuel: 10:30:16.377 [main] INFO  io.casperlabs.node.api.Servers$ - gRPC diagnostics service started on port 40402.\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabsfpuel: 10:30:16.590 [main] INFO  io.casperlabs.node.api.Servers$ - gRPC deployment service started on port 40401.\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabsfpuel: 10:30:16.658 [main] INFO  io.casperlabs.node.MetricsRuntime - No Influx configuration found\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabsfpuel: 10:30:16.668 [main] INFO  io.casperlabs.node.MetricsRuntime - Reporting metrics to InfluxDB disabled.\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabsfpuel: 10:30:16.669 [main] INFO  io.casperlabs.node.MetricsRuntime - Reporting metrics to Prometheus.\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabsfpuel: 10:30:16.695 [main] INFO  io.casperlabs.node.MetricsRuntime - Reporting metrics to Zipkin disabled.\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabsfpuel: 10:30:16.697 [main] INFO  io.casperlabs.node.MetricsRuntime - Reporting metrics to JMX.\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabsfpuel: 10:30:16.705 [main] INFO  kamon.metrics.SystemMetrics - Starting the Kamon(SystemMetrics) module\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabsfpuel: 10:30:16.787 [main] INFO  io.casperlabs.node.api.Servers$ - HTTP server started on port 40403.\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabsfpuel: 10:30:16.866 [main] INFO  i.c.c.util.comm.CasperPacketHandler$ - can't find transforms from BlockStore for the saved approvedBlock\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabsfpuel: 10:30:16.868 [main] INFO  i.c.c.util.comm.CasperPacketHandler$ - Starting in create genesis mode\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabsfpuel: 10:30:16.888 [main] WARN  i.casperlabs.casper.genesis.Genesis$ - Specified wallets file /root/.casperlabs/genesis/wallets.txt does not exist. No wallets will exist at genesis.\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabsfpuel: 10:30:17.338 [node-runner-41] INFO  i.c.c.u.c.ApproveBlockProtocol$ApproveBlockProtocolImpl - APPROVAL: Beginning send of UnapprovedBlock fc98b0ba32... to peers...\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabsfpuel: 10:30:17.397 [node-runner-41] INFO  i.c.comm.transport.TcpTransportLayer - stream to List() blob\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabsfpuel: 10:30:17.398 [node-runner-41] INFO  i.c.c.u.c.ApproveBlockProtocol$ApproveBlockProtocolImpl - APPROVAL: Sent UnapprovedBlock fc98b0ba32... to peers.\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabsfpuel: 10:30:17.409 [node-runner-41] INFO  i.c.c.u.c.ApproveBlockProtocol$ApproveBlockProtocolImpl - APPROVAL: Beginning send of ApprovedBlock fc98b0ba32... to peers...\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabsfpuel: 10:30:17.412 [node-runner-41] INFO  i.c.comm.transport.TcpTransportLayer - stream to List() blob\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabsfpuel: 10:30:17.413 [node-runner-41] INFO  i.c.c.u.c.ApproveBlockProtocol$ApproveBlockProtocolImpl - APPROVAL: Sent ApprovedBlock fc98b0ba32... to peers.\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabsfpuel: 10:30:17.975 [grpc-default-executor-0] INFO  i.c.node.casper.transport.package$ - Started transport layer on port 40400.\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabsfpuel: 10:30:18.022 [grpc-default-executor-0] INFO  io.casperlabs.node.NodeRuntime - Starting stand-alone node.\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabsfpuel: 10:30:18.031 [grpc-default-executor-0] INFO  io.casperlabs.node.NodeRuntime - Listening for traffic on casperlabs://cb74ba04085574e9f0102cc13d39f0c72219c5bb@bootstrap.casperlabsfpuel?protocol=40400&discovery=40404.\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabsfpuel: 10:30:22.449 [node-runner-41] WARN  i.c.b.BlockDagFileStorage$ - Block fc98b0ba327be98a2228eefc3b6a2cc96d7e540b1254d5b0ab18e5b3b9300f76 sender is empty\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabsfpuel: 10:30:22.534 [grpc-default-executor-0] INFO  i.c.c.util.comm.CasperPacketHandler$ - Making a transition to ApprovedBlockRecievedHandler state.\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabsfpuel: 10:30:22.552 [node-runner-41] INFO  i.c.casper.util.comm.CommUtil$ - Requested fork tip from peers\nINFO     root:wait.py:214 SATISFIED <NodeStarted('bootstrap.casperlabsfpuel', 'io.casperlabs.node.NodeRuntime - Listening for traffic on casperlabs')>\nINFO     root:wait.py:206 AWAITING <ApprovedBlockReceivedHandlerStateEntered('bootstrap.casperlabsfpuel', \"['Making a transition to ApprovedBlockRecievedHandler state.', 'Making the transition to block processing.']\")>\nINFO     root:wait.py:214 SATISFIED <ApprovedBlockReceivedHandlerStateEntered('bootstrap.casperlabsfpuel', \"['Making a transition to ApprovedBlockRecievedHandler state.', 'Making the transition to block processing.']\")>\nINFO     root:casperlabsnode.py:303 peer0.casperlabsfpuel command: run --server-bootstrap casperlabs://cb74ba04085574e9f0102cc13d39f0c72219c5bb@bootstrap.casperlabsfpuel?protocol=40400&discovery=40404 --casper-validator-private-key 901b1f0837b7e891d7c2ea0047f502fd95637e450b0226c39a97d68dd951c8a7 --server-host peer0.casperlabsfpuel --metrics-prometheus  --grpc-socket /root/.casperlabs/sockets/.casper-node.sock\nINFO     root:casperlabsnode.py:303 peer1.casperlabsfpuel command: run --server-bootstrap casperlabs://cb74ba04085574e9f0102cc13d39f0c72219c5bb@bootstrap.casperlabsfpuel?protocol=40400&discovery=40404 --casper-validator-private-key f7bfb2b3f2be909dd50beac05bece5940b1e7266816d7294291a2ff66a5d660b --server-host peer1.casperlabsfpuel --metrics-prometheus  --grpc-socket /root/.casperlabs/sockets/.casper-node.sock\nINFO     root:casperlabsnode.py:303 peer2.casperlabsfpuel command: run --server-bootstrap casperlabs://cb74ba04085574e9f0102cc13d39f0c72219c5bb@bootstrap.casperlabsfpuel?protocol=40400&discovery=40404 --casper-validator-private-key 2b173084083291ac6850cb734dffb69dfcb280aeb152f0d5be979bea7827c03a --server-host peer2.casperlabsfpuel --metrics-prometheus  --grpc-socket /root/.casperlabs/sockets/.casper-node.sock\nINFO     peers:casperlabsnode.py:268 \tpeer0.casperlabsfpuel: 10:30:28.656 [main] INFO  io.casperlabs.node.Main$ - CasperLabs node 0.3 (176160cd54206e3f9d599604b5e7a5e80e98f354)\nINFO     peers:casperlabsnode.py:268 \tpeer0.casperlabsfpuel: 10:30:28.679 [main] INFO  io.casperlabs.node.NodeEnvironment$ - Using data dir: /root/.casperlabs\nINFO     peers:casperlabsnode.py:268 \tpeer0.casperlabsfpuel: 10:30:28.697 [main] INFO  i.c.c.t.GenerateCertificateIfAbsent - No certificate found at path /root/.casperlabs/node.certificate.pem\nINFO     peers:casperlabsnode.py:268 \tpeer0.casperlabsfpuel: 10:30:28.699 [main] INFO  i.c.c.t.GenerateCertificateIfAbsent - Generating a X.509 certificate for the node\nINFO     peers:casperlabsnode.py:268 \tpeer0.casperlabsfpuel: 10:30:28.705 [main] INFO  i.c.c.t.GenerateCertificateIfAbsent - Generating a PEM secret key for the node\nINFO     peers:casperlabsnode.py:268 \tpeer0.casperlabsfpuel: 10:30:29.109 [main] INFO  io.casperlabs.comm.UPnP$ - trying to open ports using UPnP....\nINFO     root:casperlabsnode.py:303 peer3.casperlabsfpuel command: run --server-bootstrap casperlabs://cb74ba04085574e9f0102cc13d39f0c72219c5bb@bootstrap.casperlabsfpuel?protocol=40400&discovery=40404 --casper-validator-private-key 97b4fb2f783af685ef25cf150e63f41be7f46d32ddb7258a2edd092dcc4dfd75 --server-host peer3.casperlabsfpuel --metrics-prometheus  --grpc-socket /root/.casperlabs/sockets/.casper-node.sock\nINFO     peers:casperlabsnode.py:268 \tpeer1.casperlabsfpuel: 10:30:30.595 [main] INFO  io.casperlabs.node.Main$ - CasperLabs node 0.3 (176160cd54206e3f9d599604b5e7a5e80e98f354)\nINFO     peers:casperlabsnode.py:268 \tpeer1.casperlabsfpuel: 10:30:30.606 [main] INFO  io.casperlabs.node.NodeEnvironment$ - Using data dir: /root/.casperlabs\nINFO     peers:casperlabsnode.py:268 \tpeer1.casperlabsfpuel: 10:30:30.620 [main] INFO  i.c.c.t.GenerateCertificateIfAbsent - No certificate found at path /root/.casperlabs/node.certificate.pem\nINFO     peers:casperlabsnode.py:268 \tpeer1.casperlabsfpuel: 10:30:30.621 [main] INFO  i.c.c.t.GenerateCertificateIfAbsent - Generating a X.509 certificate for the node\nINFO     peers:casperlabsnode.py:268 \tpeer1.casperlabsfpuel: 10:30:30.630 [main] INFO  i.c.c.t.GenerateCertificateIfAbsent - Generating a PEM secret key for the node\nINFO     peers:casperlabsnode.py:268 \tpeer1.casperlabsfpuel: 10:30:31.034 [main] INFO  io.casperlabs.comm.UPnP$ - trying to open ports using UPnP...."}, "teardown": {"name": "teardown", "duration": 0.00022721290588378906, "outcome": "passed"}, "outcome": "failed"}}, {"id": 2, "type": "test", "attributes": {"name": "test/test_network_topology.py::test_casper_propose_and_deploy", "duration": 33.387742042541504, "run_index": 1, "setup": {"name": "setup", "duration": 0.0003237724304199219, "outcome": "passed"}, "call": {"name": "call", "duration": 33.386831760406494, "outcome": "failed", "longrepr": "command_line_options_fixture = CommandLineOptions(peer_count=2, node_startup_timeout=180, network_converge_timeout=220, receive_timeout=30, command_timeout=10, blocks=1, mount_dir=None)\ndocker_client_fixture = <docker.client.DockerClient object at 0x7f6a9a2a34e0>\n\n    def test_casper_propose_and_deploy(command_line_options_fixture, docker_client_fixture):\n        with conftest.testing_context(command_line_options_fixture, docker_client_fixture) as context:\n>           with complete_network(context) as network:\n\ntest_network_topology.py:66: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/lib/python3.6/contextlib.py:81: in __enter__\n    return next(self.gen)\ncl_node/casperlabsnode.py:787: in complete_network\n    wait_for_started_network(context.node_startup_timeout, network)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nnode_startup_timeout = 180, network = <test.cl_node.common.Network object at 0x7f6a9a18ccf8>\n\n    def wait_for_started_network(node_startup_timeout: int, network: 'Network'):\n>       for peer in network.cl_nodes:\nE       AttributeError: 'Network' object has no attribute 'cl_nodes'\n\ncl_node/wait.py:344: AttributeError", "log": "INFO     root:casperlabsnode.py:303 bootstrap.casperlabszecri command: run -s --server-host bootstrap.casperlabszecri --tls-certificate /root/.casperlabs/bootstrap/node.certificate.pem --tls-key /root/.casperlabs/bootstrap/node.key.pem --casper-validator-private-key 901b1f0837b7e891d7c2ea0047f502fd95637e450b0226c39a97d68dd951c8a7 --casper-validator-public-key 00322ba649cebf90d8bd0eeb0658ea7957bcc59ecee0676c86f4fec517c06251 --grpc-socket /root/.casperlabs/sockets/.casper-node.sock --metrics-prometheus \nINFO     root:wait.py:206 AWAITING <NodeStarted('bootstrap.casperlabszecri', 'io.casperlabs.node.NodeRuntime - Listening for traffic on casperlabs')>\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabszecri: 10:30:40.216 [main] INFO  io.casperlabs.node.Main$ - CasperLabs node 0.3 (176160cd54206e3f9d599604b5e7a5e80e98f354)\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabszecri: 10:30:40.222 [main] INFO  io.casperlabs.node.NodeEnvironment$ - Using data dir: /root/.casperlabs\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabszecri: 10:30:40.508 [main] INFO  io.casperlabs.comm.UPnP$ - trying to open ports using UPnP....\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabszecri: 10:30:49.554 [main] INFO  io.casperlabs.comm.UPnP$ - INFO - No gateway devices found\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabszecri: 10:30:49.555 [main] INFO  io.casperlabs.comm.UPnP$ - No need to open any port\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabszecri: 10:30:50.088 [main] WARN  i.c.b.BlockDagFileStorage$ - CRC file /root/.casperlabs/dagstorage/latest-messages-crc did not contain a valid CRC value\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabszecri: 10:30:50.115 [main] WARN  i.c.b.BlockDagFileStorage$ - CRC file /root/.casperlabs/dagstorage/block-metadata-crc did not contain a valid CRC value\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabszecri: 10:30:50.367 [main] INFO  io.casperlabs.node.api.Servers$ - gRPC diagnostics service started on port 40402.\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabszecri: 10:30:50.583 [main] INFO  io.casperlabs.node.api.Servers$ - gRPC deployment service started on port 40401.\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabszecri: 10:30:50.649 [main] INFO  io.casperlabs.node.MetricsRuntime - No Influx configuration found\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabszecri: 10:30:50.658 [main] INFO  io.casperlabs.node.MetricsRuntime - Reporting metrics to InfluxDB disabled.\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabszecri: 10:30:50.659 [main] INFO  io.casperlabs.node.MetricsRuntime - Reporting metrics to Prometheus.\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabszecri: 10:30:50.678 [main] INFO  io.casperlabs.node.MetricsRuntime - Reporting metrics to Zipkin disabled.\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabszecri: 10:30:50.680 [main] INFO  io.casperlabs.node.MetricsRuntime - Reporting metrics to JMX.\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabszecri: 10:30:50.687 [main] INFO  kamon.metrics.SystemMetrics - Starting the Kamon(SystemMetrics) module\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabszecri: 10:30:50.772 [main] INFO  io.casperlabs.node.api.Servers$ - HTTP server started on port 40403.\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabszecri: 10:30:50.854 [main] INFO  i.c.c.util.comm.CasperPacketHandler$ - can't find transforms from BlockStore for the saved approvedBlock\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabszecri: 10:30:50.856 [main] INFO  i.c.c.util.comm.CasperPacketHandler$ - Starting in create genesis mode\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabszecri: 10:30:50.877 [main] WARN  i.casperlabs.casper.genesis.Genesis$ - Specified wallets file /root/.casperlabs/genesis/wallets.txt does not exist. No wallets will exist at genesis.\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabszecri: 10:30:51.371 [node-runner-41] INFO  i.c.c.u.c.ApproveBlockProtocol$ApproveBlockProtocolImpl - APPROVAL: Beginning send of UnapprovedBlock 27da3b1d2e... to peers...\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabszecri: 10:30:51.436 [node-runner-41] INFO  i.c.comm.transport.TcpTransportLayer - stream to List() blob\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabszecri: 10:30:51.437 [node-runner-41] INFO  i.c.c.u.c.ApproveBlockProtocol$ApproveBlockProtocolImpl - APPROVAL: Sent UnapprovedBlock 27da3b1d2e... to peers.\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabszecri: 10:30:51.445 [node-runner-41] INFO  i.c.c.u.c.ApproveBlockProtocol$ApproveBlockProtocolImpl - APPROVAL: Beginning send of ApprovedBlock 27da3b1d2e... to peers...\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabszecri: 10:30:51.455 [node-runner-41] INFO  i.c.comm.transport.TcpTransportLayer - stream to List() blob\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabszecri: 10:30:51.458 [node-runner-41] INFO  i.c.c.u.c.ApproveBlockProtocol$ApproveBlockProtocolImpl - APPROVAL: Sent ApprovedBlock 27da3b1d2e... to peers.\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabszecri: 10:30:52.040 [grpc-default-executor-0] INFO  i.c.node.casper.transport.package$ - Started transport layer on port 40400.\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabszecri: 10:30:52.057 [grpc-default-executor-0] INFO  io.casperlabs.node.NodeRuntime - Starting stand-alone node.\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabszecri: 10:30:52.068 [grpc-default-executor-0] INFO  io.casperlabs.node.NodeRuntime - Listening for traffic on casperlabs://cb74ba04085574e9f0102cc13d39f0c72219c5bb@bootstrap.casperlabszecri?protocol=40400&discovery=40404.\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabszecri: 10:30:56.470 [node-runner-41] WARN  i.c.b.BlockDagFileStorage$ - Block 27da3b1d2eab39918b8a28189b5972f8540f6df5f1a6221146a68afe9f1ce60d sender is empty\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabszecri: 10:30:56.562 [grpc-default-executor-0] INFO  i.c.c.util.comm.CasperPacketHandler$ - Making a transition to ApprovedBlockRecievedHandler state.\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabszecri: 10:30:56.581 [node-runner-41] INFO  i.c.casper.util.comm.CommUtil$ - Requested fork tip from peers\nINFO     root:wait.py:214 SATISFIED <NodeStarted('bootstrap.casperlabszecri', 'io.casperlabs.node.NodeRuntime - Listening for traffic on casperlabs')>\nINFO     root:wait.py:206 AWAITING <ApprovedBlockReceivedHandlerStateEntered('bootstrap.casperlabszecri', \"['Making a transition to ApprovedBlockRecievedHandler state.', 'Making the transition to block processing.']\")>\nINFO     root:wait.py:214 SATISFIED <ApprovedBlockReceivedHandlerStateEntered('bootstrap.casperlabszecri', \"['Making a transition to ApprovedBlockRecievedHandler state.', 'Making the transition to block processing.']\")>\nINFO     root:casperlabsnode.py:303 peer0.casperlabszecri command: run --server-bootstrap casperlabs://cb74ba04085574e9f0102cc13d39f0c72219c5bb@bootstrap.casperlabszecri?protocol=40400&discovery=40404 --casper-validator-private-key 901b1f0837b7e891d7c2ea0047f502fd95637e450b0226c39a97d68dd951c8a7 --server-host peer0.casperlabszecri --metrics-prometheus  --grpc-socket /root/.casperlabs/sockets/.casper-node.sock\nINFO     root:casperlabsnode.py:303 peer1.casperlabszecri command: run --server-bootstrap casperlabs://cb74ba04085574e9f0102cc13d39f0c72219c5bb@bootstrap.casperlabszecri?protocol=40400&discovery=40404 --casper-validator-private-key f7bfb2b3f2be909dd50beac05bece5940b1e7266816d7294291a2ff66a5d660b --server-host peer1.casperlabszecri --metrics-prometheus  --grpc-socket /root/.casperlabs/sockets/.casper-node.sock\nINFO     root:casperlabsnode.py:303 peer2.casperlabszecri command: run --server-bootstrap casperlabs://cb74ba04085574e9f0102cc13d39f0c72219c5bb@bootstrap.casperlabszecri?protocol=40400&discovery=40404 --casper-validator-private-key 2b173084083291ac6850cb734dffb69dfcb280aeb152f0d5be979bea7827c03a --server-host peer2.casperlabszecri --metrics-prometheus  --grpc-socket /root/.casperlabs/sockets/.casper-node.sock\nINFO     peers:casperlabsnode.py:268 \tpeer0.casperlabszecri: 10:31:02.756 [main] INFO  io.casperlabs.node.Main$ - CasperLabs node 0.3 (176160cd54206e3f9d599604b5e7a5e80e98f354)\nINFO     peers:casperlabsnode.py:268 \tpeer0.casperlabszecri: 10:31:02.766 [main] INFO  io.casperlabs.node.NodeEnvironment$ - Using data dir: /root/.casperlabs\nINFO     peers:casperlabsnode.py:268 \tpeer0.casperlabszecri: 10:31:02.782 [main] INFO  i.c.c.t.GenerateCertificateIfAbsent - No certificate found at path /root/.casperlabs/node.certificate.pem\nINFO     peers:casperlabsnode.py:268 \tpeer0.casperlabszecri: 10:31:02.785 [main] INFO  i.c.c.t.GenerateCertificateIfAbsent - Generating a X.509 certificate for the node\nINFO     peers:casperlabsnode.py:268 \tpeer0.casperlabszecri: 10:31:02.793 [main] INFO  i.c.c.t.GenerateCertificateIfAbsent - Generating a PEM secret key for the node\nINFO     peers:casperlabsnode.py:268 \tpeer0.casperlabszecri: 10:31:03.201 [main] INFO  io.casperlabs.comm.UPnP$ - trying to open ports using UPnP....\nINFO     root:casperlabsnode.py:303 peer3.casperlabszecri command: run --server-bootstrap casperlabs://cb74ba04085574e9f0102cc13d39f0c72219c5bb@bootstrap.casperlabszecri?protocol=40400&discovery=40404 --casper-validator-private-key 97b4fb2f783af685ef25cf150e63f41be7f46d32ddb7258a2edd092dcc4dfd75 --server-host peer3.casperlabszecri --metrics-prometheus  --grpc-socket /root/.casperlabs/sockets/.casper-node.sock\nINFO     peers:casperlabsnode.py:268 \tpeer1.casperlabszecri: 10:31:04.753 [main] INFO  io.casperlabs.node.Main$ - CasperLabs node 0.3 (176160cd54206e3f9d599604b5e7a5e80e98f354)\nINFO     peers:casperlabsnode.py:268 \tpeer1.casperlabszecri: 10:31:04.765 [main] INFO  io.casperlabs.node.NodeEnvironment$ - Using data dir: /root/.casperlabs\nINFO     peers:casperlabsnode.py:268 \tpeer1.casperlabszecri: 10:31:04.779 [main] INFO  i.c.c.t.GenerateCertificateIfAbsent - No certificate found at path /root/.casperlabs/node.certificate.pem\nINFO     peers:casperlabsnode.py:268 \tpeer1.casperlabszecri: 10:31:04.781 [main] INFO  i.c.c.t.GenerateCertificateIfAbsent - Generating a X.509 certificate for the node\nINFO     peers:casperlabsnode.py:268 \tpeer1.casperlabszecri: 10:31:04.794 [main] INFO  i.c.c.t.GenerateCertificateIfAbsent - Generating a PEM secret key for the node"}, "teardown": {"name": "teardown", "duration": 0.0002627372741699219, "outcome": "passed"}, "outcome": "failed"}}, {"id": 3, "type": "test", "attributes": {"name": "test/test_network_topology.py::test_convergence", "duration": 5.578354835510254, "run_index": 2, "setup": {"name": "setup", "duration": 0.0003368854522705078, "outcome": "passed"}, "call": {"name": "call", "duration": 5.577681064605713, "outcome": "failed", "longrepr": "@contextlib.contextmanager\n    def started_bootstrap_node(*, context: TestingContext, network: str, socket_volume: str, container_name: str = None) -> Generator[Node, None, None]:\n        engine = make_execution_engine(\n            docker_client=context.docker,\n            name=\"bootstrap\",\n            command=EXECUTION_ENGINE_COMMAND,\n            network=network,\n            socket_volume=socket_volume,\n        )\n        bootstrap_node = make_bootstrap_node(\n            docker_client=context.docker,\n            network=network,\n            socket_volume=socket_volume,\n            bonds_file=context.bonds_file,\n            key_pair=context.bootstrap_keypair,\n            command_timeout=context.command_timeout,\n            container_name=container_name,\n        )\n        try:\n>           wait_for_node_started(bootstrap_node, context.node_startup_timeout)\n\ncl_node/casperlabsnode.py:745: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nnode = <Node(name='bootstrap.casperlabsxxtxk')>, startup_timeout = 180, times = 1\n\n    def wait_for_node_started(node: 'Node', startup_timeout: int, times: int = 1):\n        predicate = NodeStarted(node, times)\n>       wait_on_using_wall_clock_time(predicate, startup_timeout)\n\ncl_node/wait.py:248: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\npredicate = <test.cl_node.wait.NodeStarted object at 0x7f6a998fc9e8>, timeout = 180\n\n    def wait_on_using_wall_clock_time(predicate: PredicateProtocol, timeout: int) -> None:\n        logging.info(\"AWAITING {}\".format(predicate))\n    \n        elapsed = 0\n        while elapsed < timeout:\n            start_time = time.time()\n    \n            is_satisfied = predicate.is_satisfied()\n            if is_satisfied:\n                logging.info(\"SATISFIED {}\".format(predicate))\n                return\n    \n            condition_evaluation_duration = time.time() - start_time\n            elapsed = int(elapsed + condition_evaluation_duration)\n            time_left = timeout - elapsed\n    \n            # iteration duration is 15% of remaining timeout\n            # but no more than 10s and no less than 1s\n            iteration_duration = int(min(10, max(1, int(0.15 * time_left))))\n    \n>           time.sleep(iteration_duration)\nE           KeyboardInterrupt\n\ncl_node/wait.py:225: KeyboardInterrupt\n\nDuring handling of the above exception, another exception occurred:\n\nself = <docker.transport.unixconn.UnixHTTPConnectionPool object at 0x7f6a9990d550>\nconn = <docker.transport.unixconn.UnixHTTPConnection object at 0x7f6a9a1845c0>, method = 'DELETE'\nurl = '/v1.35/containers/d58fa2baa0b3d3b4a24133be94c9325174501bba1c3657017318e091d0d71411?v=True&link=False&force=True'\ntimeout = <urllib3.util.timeout.Timeout object at 0x7f6a9a184e48>, chunked = False\nhttplib_request_kw = {'body': None, 'headers': {'User-Agent': 'docker-sdk-python/3.7.2', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Length': '0'}}\ntimeout_obj = <urllib3.util.timeout.Timeout object at 0x7f6a9a184be0>, read_timeout = 60\n\n    def _make_request(self, conn, method, url, timeout=_Default, chunked=False,\n                      **httplib_request_kw):\n        \"\"\"\n        Perform a request on a given urllib connection object taken from our\n        pool.\n    \n        :param conn:\n            a connection from one of our connection pools\n    \n        :param timeout:\n            Socket timeout in seconds for the request. This can be a\n            float or integer, which will set the same timeout value for\n            the socket connect and the socket read, or an instance of\n            :class:`urllib3.util.Timeout`, which gives you more fine-grained\n            control over your timeouts.\n        \"\"\"\n        self.num_requests += 1\n    \n        timeout_obj = self._get_timeout(timeout)\n        timeout_obj.start_connect()\n        conn.timeout = timeout_obj.connect_timeout\n    \n        # Trigger any extra validation we need to do.\n        try:\n            self._validate_conn(conn)\n        except (SocketTimeout, BaseSSLError) as e:\n            # Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\n            self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)\n            raise\n    \n        # conn.request() calls httplib.*.request, not the method in\n        # urllib3.request. It also calls makefile (recv) on the socket.\n        if chunked:\n            conn.request_chunked(method, url, **httplib_request_kw)\n        else:\n            conn.request(method, url, **httplib_request_kw)\n    \n        # Reset the timeout for the recv() on the socket\n        read_timeout = timeout_obj.read_timeout\n    \n        # App Engine doesn't have a sock attr\n        if getattr(conn, 'sock', None):\n            # In Python 3 socket.py will catch EAGAIN and return None when you\n            # try and read into the file pointer created by http.client, which\n            # instead raises a BadStatusLine exception. Instead of catching\n            # the exception and assuming all BadStatusLine exceptions are read\n            # timeouts, check for a zero timeout before making the request.\n            if read_timeout == 0:\n                raise ReadTimeoutError(\n                    self, url, \"Read timed out. (read timeout=%s)\" % read_timeout)\n            if read_timeout is Timeout.DEFAULT_TIMEOUT:\n                conn.sock.settimeout(socket.getdefaulttimeout())\n            else:  # None or a value\n                conn.sock.settimeout(read_timeout)\n    \n        # Receive the response from the server\n        try:\n            try:  # Python 2.7, use buffering of HTTP responses\n>               httplib_response = conn.getresponse(buffering=True)\nE               TypeError: getresponse() got an unexpected keyword argument 'buffering'\n\n../../../.local/share/virtualenvs/integration-testing-tsf_FPlY/lib/python3.6/site-packages/urllib3/connectionpool.py:377: TypeError\n\nDuring handling of the above exception, another exception occurred:\n\ndocker_client = <docker.client.DockerClient object at 0x7f6a9a2a34e0>\n\n    @contextlib.contextmanager\n    def docker_volume(docker_client: \"DockerClient\") -> Generator[str, None, None]:\n        volume_name = f\"casperlabs{random_string(5)}\"\n        docker_client.volumes.create(name=volume_name, driver=\"local\")\n        try:\n>           yield volume_name\n\ncl_node/casperlabsnode.py:719: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ncontext = TestingContext(peer_count=2, node_startup_timeout=180, network_converge_timeout=220, receive_timeout=30, command_timeo...edc8762c47b1bbb47c29f191ba43ad7e1d47e5427a6e583a88e0e')], docker=<docker.client.DockerClient object at 0x7f6a9a2a34e0>)\n\n    @contextlib.contextmanager\n    def docker_network_with_started_bootstrap(context, *, container_name=None):\n        with docker_network(context.docker) as network:\n            with docker_volume(context.docker) as volume:\n                with started_bootstrap_node(context=context,\n                                            network=network,\n                                            socket_volume=volume,\n>                                           container_name=container_name) as node:\n\ncl_node/casperlabsnode.py:759: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <contextlib._GeneratorContextManager object at 0x7f6a9a184a58>\n\n    def __enter__(self):\n        try:\n>           return next(self.gen)\n\n/usr/lib/python3.6/contextlib.py:81: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    @contextlib.contextmanager\n    def started_bootstrap_node(*, context: TestingContext, network: str, socket_volume: str, container_name: str = None) -> Generator[Node, None, None]:\n        engine = make_execution_engine(\n            docker_client=context.docker,\n            name=\"bootstrap\",\n            command=EXECUTION_ENGINE_COMMAND,\n            network=network,\n            socket_volume=socket_volume,\n        )\n        bootstrap_node = make_bootstrap_node(\n            docker_client=context.docker,\n            network=network,\n            socket_volume=socket_volume,\n            bonds_file=context.bonds_file,\n            key_pair=context.bootstrap_keypair,\n            command_timeout=context.command_timeout,\n            container_name=container_name,\n        )\n        try:\n            wait_for_node_started(bootstrap_node, context.node_startup_timeout)\n            yield bootstrap_node\n        finally:\n            engine.remove(force=True, v=True)\n>           bootstrap_node.cleanup()\n\ncl_node/casperlabsnode.py:749: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <Node(name='bootstrap.casperlabsxxtxk')>\n\n    def cleanup(self) -> None:\n>       self.container.remove(force=True, v=True)\n\ncl_node/casperlabsnode.py:142: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <Container: d58fa2baa0>, kwargs = {'force': True, 'v': True}\n\n    def remove(self, **kwargs):\n        \"\"\"\n        Remove this container. Similar to the ``docker rm`` command.\n    \n        Args:\n            v (bool): Remove the volumes associated with the container\n            link (bool): Remove the specified link and not the underlying\n                container\n            force (bool): Force the removal of a running container (uses\n                ``SIGKILL``)\n    \n        Raises:\n            :py:class:`docker.errors.APIError`\n                If the server returns an error.\n        \"\"\"\n>       return self.client.api.remove_container(self.id, **kwargs)\n\n../../../.local/share/virtualenvs/integration-testing-tsf_FPlY/lib/python3.6/site-packages/docker/models/containers.py:339: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <docker.api.client.APIClient object at 0x7f6a9a2a3048>\nresource_id = 'd58fa2baa0b3d3b4a24133be94c9325174501bba1c3657017318e091d0d71411', args = ()\nkwargs = {'force': True, 'v': True}\n\n    @functools.wraps(f)\n    def wrapped(self, resource_id=None, *args, **kwargs):\n        if resource_id is None and kwargs.get(resource_name):\n            resource_id = kwargs.pop(resource_name)\n        if isinstance(resource_id, dict):\n            resource_id = resource_id.get('Id', resource_id.get('ID'))\n        if not resource_id:\n            raise errors.NullResource(\n                'Resource ID was not provided'\n            )\n>       return f(self, resource_id, *args, **kwargs)\n\n../../../.local/share/virtualenvs/integration-testing-tsf_FPlY/lib/python3.6/site-packages/docker/utils/decorators.py:19: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <docker.api.client.APIClient object at 0x7f6a9a2a3048>\ncontainer = 'd58fa2baa0b3d3b4a24133be94c9325174501bba1c3657017318e091d0d71411', v = True, link = False, force = True\n\n    @utils.check_resource('container')\n    def remove_container(self, container, v=False, link=False, force=False):\n        \"\"\"\n        Remove a container. Similar to the ``docker rm`` command.\n    \n        Args:\n            container (str): The container to remove\n            v (bool): Remove the volumes associated with the container\n            link (bool): Remove the specified link and not the underlying\n                container\n            force (bool): Force the removal of a running container (uses\n                ``SIGKILL``)\n    \n        Raises:\n            :py:class:`docker.errors.APIError`\n                If the server returns an error.\n        \"\"\"\n        params = {'v': v, 'link': link, 'force': force}\n        res = self._delete(\n>           self._url(\"/containers/{0}\", container), params=params\n        )\n\n../../../.local/share/virtualenvs/integration-testing-tsf_FPlY/lib/python3.6/site-packages/docker/api/container.py:990: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <docker.api.client.APIClient object at 0x7f6a9a2a3048>\nargs = ('http+docker://localhost/v1.35/containers/d58fa2baa0b3d3b4a24133be94c9325174501bba1c3657017318e091d0d71411',)\nkwargs = {'params': {'force': True, 'link': False, 'v': True}}\n\n    def inner(self, *args, **kwargs):\n        if 'HttpHeaders' in self._general_configs:\n            if not kwargs.get('headers'):\n                kwargs['headers'] = self._general_configs['HttpHeaders']\n            else:\n                kwargs['headers'].update(self._general_configs['HttpHeaders'])\n>       return f(self, *args, **kwargs)\n\n../../../.local/share/virtualenvs/integration-testing-tsf_FPlY/lib/python3.6/site-packages/docker/utils/decorators.py:46: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <docker.api.client.APIClient object at 0x7f6a9a2a3048>\nurl = 'http+docker://localhost/v1.35/containers/d58fa2baa0b3d3b4a24133be94c9325174501bba1c3657017318e091d0d71411'\nkwargs = {'params': {'force': True, 'link': False, 'v': True}, 'timeout': 60}\n\n    @update_headers\n    def _delete(self, url, **kwargs):\n>       return self.delete(url, **self._set_request_timeout(kwargs))\n\n../../../.local/share/virtualenvs/integration-testing-tsf_FPlY/lib/python3.6/site-packages/docker/api/client.py:238: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <docker.api.client.APIClient object at 0x7f6a9a2a3048>\nurl = 'http+docker://localhost/v1.35/containers/d58fa2baa0b3d3b4a24133be94c9325174501bba1c3657017318e091d0d71411'\nkwargs = {'params': {'force': True, 'link': False, 'v': True}, 'timeout': 60}\n\n    def delete(self, url, **kwargs):\n        r\"\"\"Sends a DELETE request. Returns :class:`Response` object.\n    \n        :param url: URL for the new :class:`Request` object.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n    \n>       return self.request('DELETE', url, **kwargs)\n\n../../../.local/share/virtualenvs/integration-testing-tsf_FPlY/lib/python3.6/site-packages/requests/sessions.py:615: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <docker.api.client.APIClient object at 0x7f6a9a2a3048>, method = 'DELETE'\nurl = 'http+docker://localhost/v1.35/containers/d58fa2baa0b3d3b4a24133be94c9325174501bba1c3657017318e091d0d71411'\nparams = {'force': True, 'link': False, 'v': True}, data = None, headers = None, cookies = None, files = None\nauth = None, timeout = 60, allow_redirects = True, proxies = {}, hooks = None, stream = None, verify = None\ncert = None, json = None\n\n    def request(self, method, url,\n            params=None, data=None, headers=None, cookies=None, files=None,\n            auth=None, timeout=None, allow_redirects=True, proxies=None,\n            hooks=None, stream=None, verify=None, cert=None, json=None):\n        \"\"\"Constructs a :class:`Request <Request>`, prepares it and sends it.\n        Returns :class:`Response <Response>` object.\n    \n        :param method: method for the new :class:`Request` object.\n        :param url: URL for the new :class:`Request` object.\n        :param params: (optional) Dictionary or bytes to be sent in the query\n            string for the :class:`Request`.\n        :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n            object to send in the body of the :class:`Request`.\n        :param json: (optional) json to send in the body of the\n            :class:`Request`.\n        :param headers: (optional) Dictionary of HTTP Headers to send with the\n            :class:`Request`.\n        :param cookies: (optional) Dict or CookieJar object to send with the\n            :class:`Request`.\n        :param files: (optional) Dictionary of ``'filename': file-like-objects``\n            for multipart encoding upload.\n        :param auth: (optional) Auth tuple or callable to enable\n            Basic/Digest/Custom HTTP Auth.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple\n        :param allow_redirects: (optional) Set to True by default.\n        :type allow_redirects: bool\n        :param proxies: (optional) Dictionary mapping protocol or protocol and\n            hostname to the URL of the proxy.\n        :param stream: (optional) whether to immediately download the response\n            content. Defaults to ``False``.\n        :param verify: (optional) Either a boolean, in which case it controls whether we verify\n            the server's TLS certificate, or a string, in which case it must be a path\n            to a CA bundle to use. Defaults to ``True``.\n        :param cert: (optional) if String, path to ssl client cert file (.pem).\n            If Tuple, ('cert', 'key') pair.\n        :rtype: requests.Response\n        \"\"\"\n        # Create the Request.\n        req = Request(\n            method=method.upper(),\n            url=url,\n            headers=headers,\n            files=files,\n            data=data or {},\n            json=json,\n            params=params or {},\n            auth=auth,\n            cookies=cookies,\n            hooks=hooks,\n        )\n        prep = self.prepare_request(req)\n    \n        proxies = proxies or {}\n    \n        settings = self.merge_environment_settings(\n            prep.url, proxies, stream, verify, cert\n        )\n    \n        # Send the request.\n        send_kwargs = {\n            'timeout': timeout,\n            'allow_redirects': allow_redirects,\n        }\n        send_kwargs.update(settings)\n>       resp = self.send(prep, **send_kwargs)\n\n../../../.local/share/virtualenvs/integration-testing-tsf_FPlY/lib/python3.6/site-packages/requests/sessions.py:533: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <docker.api.client.APIClient object at 0x7f6a9a2a3048>, request = <PreparedRequest [DELETE]>\nkwargs = {'cert': None, 'proxies': OrderedDict(), 'stream': False, 'timeout': 60, ...}, allow_redirects = True\nstream = False, hooks = {'response': []}\nadapter = <docker.transport.unixconn.UnixHTTPAdapter object at 0x7f6a9a2a3dd8>, start = 1558261874.7762954\n\n    def send(self, request, **kwargs):\n        \"\"\"Send a given PreparedRequest.\n    \n        :rtype: requests.Response\n        \"\"\"\n        # Set defaults that the hooks can utilize to ensure they always have\n        # the correct parameters to reproduce the previous request.\n        kwargs.setdefault('stream', self.stream)\n        kwargs.setdefault('verify', self.verify)\n        kwargs.setdefault('cert', self.cert)\n        kwargs.setdefault('proxies', self.proxies)\n    \n        # It's possible that users might accidentally send a Request object.\n        # Guard against that specific failure case.\n        if isinstance(request, Request):\n            raise ValueError('You can only send PreparedRequests.')\n    \n        # Set up variables needed for resolve_redirects and dispatching of hooks\n        allow_redirects = kwargs.pop('allow_redirects', True)\n        stream = kwargs.get('stream')\n        hooks = request.hooks\n    \n        # Get the appropriate adapter to use\n        adapter = self.get_adapter(url=request.url)\n    \n        # Start time (approximately) of the request\n        start = preferred_clock()\n    \n        # Send the request\n>       r = adapter.send(request, **kwargs)\n\n../../../.local/share/virtualenvs/integration-testing-tsf_FPlY/lib/python3.6/site-packages/requests/sessions.py:646: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <docker.transport.unixconn.UnixHTTPAdapter object at 0x7f6a9a2a3dd8>, request = <PreparedRequest [DELETE]>\nstream = False, timeout = <urllib3.util.timeout.Timeout object at 0x7f6a998e7978>, verify = True, cert = None\nproxies = OrderedDict()\n\n    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):\n        \"\"\"Sends PreparedRequest object. Returns Response object.\n    \n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple or urllib3 Timeout object\n        :param verify: (optional) Either a boolean, in which case it controls whether\n            we verify the server's TLS certificate, or a string, in which case it\n            must be a path to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        :rtype: requests.Response\n        \"\"\"\n    \n        try:\n            conn = self.get_connection(request.url, proxies)\n        except LocationValueError as e:\n            raise InvalidURL(e, request=request)\n    \n        self.cert_verify(conn, request.url, verify, cert)\n        url = self.request_url(request, proxies)\n        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)\n    \n        chunked = not (request.body is None or 'Content-Length' in request.headers)\n    \n        if isinstance(timeout, tuple):\n            try:\n                connect, read = timeout\n                timeout = TimeoutSauce(connect=connect, read=read)\n            except ValueError as e:\n                # this may raise a string formatting error.\n                err = (\"Invalid timeout {}. Pass a (connect, read) \"\n                       \"timeout tuple, or a single float to set \"\n                       \"both timeouts to the same value\".format(timeout))\n                raise ValueError(err)\n        elif isinstance(timeout, TimeoutSauce):\n            pass\n        else:\n            timeout = TimeoutSauce(connect=timeout, read=timeout)\n    \n        try:\n            if not chunked:\n                resp = conn.urlopen(\n                    method=request.method,\n                    url=url,\n                    body=request.body,\n                    headers=request.headers,\n                    redirect=False,\n                    assert_same_host=False,\n                    preload_content=False,\n                    decode_content=False,\n                    retries=self.max_retries,\n>                   timeout=timeout\n                )\n\n../../../.local/share/virtualenvs/integration-testing-tsf_FPlY/lib/python3.6/site-packages/requests/adapters.py:449: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <docker.transport.unixconn.UnixHTTPConnectionPool object at 0x7f6a9990d550>, method = 'DELETE'\nurl = '/v1.35/containers/d58fa2baa0b3d3b4a24133be94c9325174501bba1c3657017318e091d0d71411?v=True&link=False&force=True'\nbody = None\nheaders = {'User-Agent': 'docker-sdk-python/3.7.2', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Length': '0'}\nretries = Retry(total=0, connect=None, read=False, redirect=None, status=None), redirect = False\nassert_same_host = False, timeout = <urllib3.util.timeout.Timeout object at 0x7f6a998e7978>, pool_timeout = None\nrelease_conn = False, chunked = False, body_pos = None\nresponse_kw = {'decode_content': False, 'preload_content': False}, conn = None, release_this_conn = True, err = None\nclean_exit = False, timeout_obj = <urllib3.util.timeout.Timeout object at 0x7f6a9a184e48>, is_new_proxy_conn = False\n\n    def urlopen(self, method, url, body=None, headers=None, retries=None,\n                redirect=True, assert_same_host=True, timeout=_Default,\n                pool_timeout=None, release_conn=None, chunked=False,\n                body_pos=None, **response_kw):\n        \"\"\"\n        Get a connection from the pool and perform an HTTP request. This is the\n        lowest level call for making a request, so you'll need to specify all\n        the raw details.\n    \n        .. note::\n    \n           More commonly, it's appropriate to use a convenience method provided\n           by :class:`.RequestMethods`, such as :meth:`request`.\n    \n        .. note::\n    \n           `release_conn` will only behave as expected if\n           `preload_content=False` because we want to make\n           `preload_content=False` the default behaviour someday soon without\n           breaking backwards compatibility.\n    \n        :param method:\n            HTTP request method (such as GET, POST, PUT, etc.)\n    \n        :param body:\n            Data to send in the request body (useful for creating\n            POST requests, see HTTPConnectionPool.post_url for\n            more convenience).\n    \n        :param headers:\n            Dictionary of custom headers to send, such as User-Agent,\n            If-None-Match, etc. If None, pool headers are used. If provided,\n            these headers completely replace any pool-specific headers.\n    \n        :param retries:\n            Configure the number of retries to allow before raising a\n            :class:`~urllib3.exceptions.MaxRetryError` exception.\n    \n            Pass ``None`` to retry until you receive a response. Pass a\n            :class:`~urllib3.util.retry.Retry` object for fine-grained control\n            over different types of retries.\n            Pass an integer number to retry connection errors that many times,\n            but no other types of errors. Pass zero to never retry.\n    \n            If ``False``, then retries are disabled and any exception is raised\n            immediately. Also, instead of raising a MaxRetryError on redirects,\n            the redirect response will be returned.\n    \n        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.\n    \n        :param redirect:\n            If True, automatically handle redirects (status codes 301, 302,\n            303, 307, 308). Each redirect counts as a retry. Disabling retries\n            will disable redirect, too.\n    \n        :param assert_same_host:\n            If ``True``, will make sure that the host of the pool requests is\n            consistent else will raise HostChangedError. When False, you can\n            use the pool on an HTTP proxy and request foreign hosts.\n    \n        :param timeout:\n            If specified, overrides the default timeout for this one\n            request. It may be a float (in seconds) or an instance of\n            :class:`urllib3.util.Timeout`.\n    \n        :param pool_timeout:\n            If set and the pool is set to block=True, then this method will\n            block for ``pool_timeout`` seconds and raise EmptyPoolError if no\n            connection is available within the time period.\n    \n        :param release_conn:\n            If False, then the urlopen call will not release the connection\n            back into the pool once a response is received (but will release if\n            you read the entire contents of the response such as when\n            `preload_content=True`). This is useful if you're not preloading\n            the response's content immediately. You will need to call\n            ``r.release_conn()`` on the response ``r`` to return the connection\n            back into the pool. If None, it takes the value of\n            ``response_kw.get('preload_content', True)``.\n    \n        :param chunked:\n            If True, urllib3 will send the body using chunked transfer\n            encoding. Otherwise, urllib3 will send the body using the standard\n            content-length form. Defaults to False.\n    \n        :param int body_pos:\n            Position to seek to in file-like body in the event of a retry or\n            redirect. Typically this won't need to be set because urllib3 will\n            auto-populate the value when needed.\n    \n        :param \\\\**response_kw:\n            Additional parameters are passed to\n            :meth:`urllib3.response.HTTPResponse.from_httplib`\n        \"\"\"\n        if headers is None:\n            headers = self.headers\n    \n        if not isinstance(retries, Retry):\n            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)\n    \n        if release_conn is None:\n            release_conn = response_kw.get('preload_content', True)\n    \n        # Check host\n        if assert_same_host and not self.is_same_host(url):\n            raise HostChangedError(self, url, retries)\n    \n        conn = None\n    \n        # Track whether `conn` needs to be released before\n        # returning/raising/recursing. Update this variable if necessary, and\n        # leave `release_conn` constant throughout the function. That way, if\n        # the function recurses, the original value of `release_conn` will be\n        # passed down into the recursive call, and its value will be respected.\n        #\n        # See issue #651 [1] for details.\n        #\n        # [1] <https://github.com/shazow/urllib3/issues/651>\n        release_this_conn = release_conn\n    \n        # Merge the proxy headers. Only do this in HTTP. We have to copy the\n        # headers dict so we can safely change it without those changes being\n        # reflected in anyone else's copy.\n        if self.scheme == 'http':\n            headers = headers.copy()\n            headers.update(self.proxy_headers)\n    \n        # Must keep the exception bound to a separate variable or else Python 3\n        # complains about UnboundLocalError.\n        err = None\n    \n        # Keep track of whether we cleanly exited the except block. This\n        # ensures we do proper cleanup in finally.\n        clean_exit = False\n    \n        # Rewind body position, if needed. Record current position\n        # for future rewinds in the event of a redirect/retry.\n        body_pos = set_file_position(body, body_pos)\n    \n        try:\n            # Request a connection from the queue.\n            timeout_obj = self._get_timeout(timeout)\n            conn = self._get_conn(timeout=pool_timeout)\n    \n            conn.timeout = timeout_obj.connect_timeout\n    \n            is_new_proxy_conn = self.proxy is not None and not getattr(conn, 'sock', None)\n            if is_new_proxy_conn:\n                self._prepare_proxy(conn)\n    \n            # Make the request on the httplib connection object.\n            httplib_response = self._make_request(conn, method, url,\n                                                  timeout=timeout_obj,\n                                                  body=body, headers=headers,\n>                                                 chunked=chunked)\n\n../../../.local/share/virtualenvs/integration-testing-tsf_FPlY/lib/python3.6/site-packages/urllib3/connectionpool.py:600: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <docker.transport.unixconn.UnixHTTPConnectionPool object at 0x7f6a9990d550>\nconn = <docker.transport.unixconn.UnixHTTPConnection object at 0x7f6a9a1845c0>, method = 'DELETE'\nurl = '/v1.35/containers/d58fa2baa0b3d3b4a24133be94c9325174501bba1c3657017318e091d0d71411?v=True&link=False&force=True'\ntimeout = <urllib3.util.timeout.Timeout object at 0x7f6a9a184e48>, chunked = False\nhttplib_request_kw = {'body': None, 'headers': {'User-Agent': 'docker-sdk-python/3.7.2', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Length': '0'}}\ntimeout_obj = <urllib3.util.timeout.Timeout object at 0x7f6a9a184be0>, read_timeout = 60\n\n    def _make_request(self, conn, method, url, timeout=_Default, chunked=False,\n                      **httplib_request_kw):\n        \"\"\"\n        Perform a request on a given urllib connection object taken from our\n        pool.\n    \n        :param conn:\n            a connection from one of our connection pools\n    \n        :param timeout:\n            Socket timeout in seconds for the request. This can be a\n            float or integer, which will set the same timeout value for\n            the socket connect and the socket read, or an instance of\n            :class:`urllib3.util.Timeout`, which gives you more fine-grained\n            control over your timeouts.\n        \"\"\"\n        self.num_requests += 1\n    \n        timeout_obj = self._get_timeout(timeout)\n        timeout_obj.start_connect()\n        conn.timeout = timeout_obj.connect_timeout\n    \n        # Trigger any extra validation we need to do.\n        try:\n            self._validate_conn(conn)\n        except (SocketTimeout, BaseSSLError) as e:\n            # Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\n            self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)\n            raise\n    \n        # conn.request() calls httplib.*.request, not the method in\n        # urllib3.request. It also calls makefile (recv) on the socket.\n        if chunked:\n            conn.request_chunked(method, url, **httplib_request_kw)\n        else:\n            conn.request(method, url, **httplib_request_kw)\n    \n        # Reset the timeout for the recv() on the socket\n        read_timeout = timeout_obj.read_timeout\n    \n        # App Engine doesn't have a sock attr\n        if getattr(conn, 'sock', None):\n            # In Python 3 socket.py will catch EAGAIN and return None when you\n            # try and read into the file pointer created by http.client, which\n            # instead raises a BadStatusLine exception. Instead of catching\n            # the exception and assuming all BadStatusLine exceptions are read\n            # timeouts, check for a zero timeout before making the request.\n            if read_timeout == 0:\n                raise ReadTimeoutError(\n                    self, url, \"Read timed out. (read timeout=%s)\" % read_timeout)\n            if read_timeout is Timeout.DEFAULT_TIMEOUT:\n                conn.sock.settimeout(socket.getdefaulttimeout())\n            else:  # None or a value\n                conn.sock.settimeout(read_timeout)\n    \n        # Receive the response from the server\n        try:\n            try:  # Python 2.7, use buffering of HTTP responses\n                httplib_response = conn.getresponse(buffering=True)\n            except TypeError:  # Python 3\n                try:\n>                   httplib_response = conn.getresponse()\n\n../../../.local/share/virtualenvs/integration-testing-tsf_FPlY/lib/python3.6/site-packages/urllib3/connectionpool.py:380: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <docker.transport.unixconn.UnixHTTPConnection object at 0x7f6a9a1845c0>\n\n    def getresponse(self):\n        \"\"\"Get the response from the server.\n    \n        If the HTTPConnection is in the correct state, returns an\n        instance of HTTPResponse or of whatever object is returned by\n        the response_class variable.\n    \n        If a request has not been sent or if a previous response has\n        not be handled, ResponseNotReady is raised.  If the HTTP\n        response indicates that the connection should be closed, then\n        it will be closed before the response is returned.  When the\n        connection is closed, the underlying socket is closed.\n        \"\"\"\n    \n        # if a prior response has been completed, then forget about it.\n        if self.__response and self.__response.isclosed():\n            self.__response = None\n    \n        # if a prior response exists, then it must be completed (otherwise, we\n        # cannot read this response's header to determine the connection-close\n        # behavior)\n        #\n        # note: if a prior response existed, but was connection-close, then the\n        # socket and response were made independent of this HTTPConnection\n        # object since a new request requires that we open a whole new\n        # connection\n        #\n        # this means the prior response had one of two states:\n        #   1) will_close: this connection was reset and the prior socket and\n        #                  response operate independently\n        #   2) persistent: the response was retained and we await its\n        #                  isclosed() status to become true.\n        #\n        if self.__state != _CS_REQ_SENT or self.__response:\n            raise ResponseNotReady(self.__state)\n    \n        if self.debuglevel > 0:\n            response = self.response_class(self.sock, self.debuglevel,\n                                           method=self._method)\n        else:\n            response = self.response_class(self.sock, method=self._method)\n    \n        try:\n            try:\n>               response.begin()\n\n/usr/lib/python3.6/http/client.py:1331: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <docker.transport.unixconn.UnixHTTPResponse object at 0x7f6a99945278>\n\n    def begin(self):\n        if self.headers is not None:\n            # we've already started reading the response\n            return\n    \n        # read until we get a non-100 response\n        while True:\n>           version, status, reason = self._read_status()\n\n/usr/lib/python3.6/http/client.py:297: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <docker.transport.unixconn.UnixHTTPResponse object at 0x7f6a99945278>\n\n    def _read_status(self):\n>       line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n\n/usr/lib/python3.6/http/client.py:258: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <socket.SocketIO object at 0x7f6a999452e8>, b = <memory at 0x7f6a9914e4c8>\n\n    def readinto(self, b):\n        \"\"\"Read up to len(b) bytes into the writable buffer *b* and return\n        the number of bytes read.  If the socket is non-blocking and no bytes\n        are available, None is returned.\n    \n        If *b* is non-empty, a 0 return value indicates that the connection\n        was shutdown at the other end.\n        \"\"\"\n        self._checkClosed()\n        self._checkReadable()\n        if self._timeout_occurred:\n            raise OSError(\"cannot read from timed out object\")\n        while True:\n            try:\n>               return self._sock.recv_into(b)\nE               KeyboardInterrupt\n\n/usr/lib/python3.6/socket.py:586: KeyboardInterrupt\n\nDuring handling of the above exception, another exception occurred:\n\nself = <docker.api.client.APIClient object at 0x7f6a9a2a3048>, response = <Response [409]>\n\n    def _raise_for_status(self, response):\n        \"\"\"Raises stored :class:`APIError`, if one occurred.\"\"\"\n        try:\n>           response.raise_for_status()\n\n../../../.local/share/virtualenvs/integration-testing-tsf_FPlY/lib/python3.6/site-packages/docker/api/client.py:261: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <Response [409]>\n\n    def raise_for_status(self):\n        \"\"\"Raises stored :class:`HTTPError`, if one occurred.\"\"\"\n    \n        http_error_msg = ''\n        if isinstance(self.reason, bytes):\n            # We attempt to decode utf-8 first because some servers\n            # choose to localize their reason strings. If the string\n            # isn't utf-8, we fall back to iso-8859-1 for all other\n            # encodings. (See PR #3538)\n            try:\n                reason = self.reason.decode('utf-8')\n            except UnicodeDecodeError:\n                reason = self.reason.decode('iso-8859-1')\n        else:\n            reason = self.reason\n    \n        if 400 <= self.status_code < 500:\n            http_error_msg = u'%s Client Error: %s for url: %s' % (self.status_code, reason, self.url)\n    \n        elif 500 <= self.status_code < 600:\n            http_error_msg = u'%s Server Error: %s for url: %s' % (self.status_code, reason, self.url)\n    \n        if http_error_msg:\n>           raise HTTPError(http_error_msg, response=self)\nE           requests.exceptions.HTTPError: 409 Client Error: Conflict for url: http+docker://localhost/v1.35/volumes/casperlabshhkaz\n\n../../../.local/share/virtualenvs/integration-testing-tsf_FPlY/lib/python3.6/site-packages/requests/models.py:940: HTTPError\n\nDuring handling of the above exception, another exception occurred:\n\ndocker_client = <docker.client.DockerClient object at 0x7f6a9a2a34e0>\n\n    @contextlib.contextmanager\n    def docker_network(docker_client: \"DockerClient\") -> Generator[str, None, None]:\n        network_name = f\"casperlabs{random_string(5)}\"\n        docker_client.networks.create(network_name, driver=\"bridge\")\n        try:\n>           yield network_name\n\ncl_node/casperlabsnode.py:707: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ncontext = TestingContext(peer_count=2, node_startup_timeout=180, network_converge_timeout=220, receive_timeout=30, command_timeo...edc8762c47b1bbb47c29f191ba43ad7e1d47e5427a6e583a88e0e')], docker=<docker.client.DockerClient object at 0x7f6a9a2a34e0>)\n\n    @contextlib.contextmanager\n    def docker_network_with_started_bootstrap(context, *, container_name=None):\n        with docker_network(context.docker) as network:\n            with docker_volume(context.docker) as volume:\n                with started_bootstrap_node(context=context,\n                                            network=network,\n                                            socket_volume=volume,\n                                            container_name=container_name) as node:\n>                   yield node\n\ncl_node/casperlabsnode.py:760: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <contextlib._GeneratorContextManager object at 0x7f6a998fc048>, type = <class 'KeyboardInterrupt'>\nvalue = KeyboardInterrupt(), traceback = <traceback object at 0x7f6a9a169888>\n\n    def __exit__(self, type, value, traceback):\n        if type is None:\n            try:\n                next(self.gen)\n            except StopIteration:\n                return False\n            else:\n                raise RuntimeError(\"generator didn't stop\")\n        else:\n            if value is None:\n                # Need to force instantiation so we can reliably\n                # tell if we get the same exception back\n                value = type()\n            try:\n>               self.gen.throw(type, value, traceback)\n\n/usr/lib/python3.6/contextlib.py:99: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ndocker_client = <docker.client.DockerClient object at 0x7f6a9a2a34e0>\n\n    @contextlib.contextmanager\n    def docker_volume(docker_client: \"DockerClient\") -> Generator[str, None, None]:\n        volume_name = f\"casperlabs{random_string(5)}\"\n        docker_client.volumes.create(name=volume_name, driver=\"local\")\n        try:\n            yield volume_name\n        finally:\n            for volume in docker_client.volumes.list():\n                if volume_name == volume.name:\n>                   volume.remove()\n\ncl_node/casperlabsnode.py:723: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <Volume: casperlabs>, force = False\n\n    def remove(self, force=False):\n        \"\"\"\n        Remove this volume.\n    \n        Args:\n            force (bool): Force removal of volumes that were already removed\n                out of band by the volume driver plugin.\n        Raises:\n            :py:class:`docker.errors.APIError`\n                If volume failed to remove.\n        \"\"\"\n>       return self.client.api.remove_volume(self.id, force=force)\n\n../../../.local/share/virtualenvs/integration-testing-tsf_FPlY/lib/python3.6/site-packages/docker/models/volumes.py:25: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <docker.api.client.APIClient object at 0x7f6a9a2a3048>, name = 'casperlabshhkaz', force = False\n\n    def remove_volume(self, name, force=False):\n        \"\"\"\n        Remove a volume. Similar to the ``docker volume rm`` command.\n    \n        Args:\n            name (str): The volume's name\n            force (bool): Force removal of volumes that were already removed\n                out of band by the volume driver plugin.\n    \n        Raises:\n            :py:class:`docker.errors.APIError`\n                If volume failed to remove.\n        \"\"\"\n        params = {}\n        if force:\n            if utils.version_lt(self._version, '1.25'):\n                raise errors.InvalidVersion(\n                    'force removal was introduced in API 1.25'\n                )\n            params = {'force': force}\n    \n        url = self._url('/volumes/{0}', name, params=params)\n        resp = self._delete(url)\n>       self._raise_for_status(resp)\n\n../../../.local/share/virtualenvs/integration-testing-tsf_FPlY/lib/python3.6/site-packages/docker/api/volume.py:161: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <docker.api.client.APIClient object at 0x7f6a9a2a3048>, response = <Response [409]>\n\n    def _raise_for_status(self, response):\n        \"\"\"Raises stored :class:`APIError`, if one occurred.\"\"\"\n        try:\n            response.raise_for_status()\n        except requests.exceptions.HTTPError as e:\n>           raise create_api_error_from_http_exception(e)\n\n../../../.local/share/virtualenvs/integration-testing-tsf_FPlY/lib/python3.6/site-packages/docker/api/client.py:263: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ne = HTTPError('409 Client Error: Conflict for url: http+docker://localhost/v1.35/volumes/casperlabshhkaz',)\n\n    def create_api_error_from_http_exception(e):\n        \"\"\"\n        Create a suitable APIError from requests.exceptions.HTTPError.\n        \"\"\"\n        response = e.response\n        try:\n            explanation = response.json()['message']\n        except ValueError:\n            explanation = (response.content or '').strip()\n        cls = APIError\n        if response.status_code == 404:\n            if explanation and ('No such image' in str(explanation) or\n                                'not found: does not exist or no pull access'\n                                in str(explanation) or\n                                'repository does not exist' in str(explanation)):\n                cls = ImageNotFound\n            else:\n                cls = NotFound\n>       raise cls(e, response=response, explanation=explanation)\nE       docker.errors.APIError: 409 Client Error: Conflict (\"remove casperlabshhkaz: volume is in use - [d58fa2baa0b3d3b4a24133be94c9325174501bba1c3657017318e091d0d71411]\")\n\n../../../.local/share/virtualenvs/integration-testing-tsf_FPlY/lib/python3.6/site-packages/docker/errors.py:31: APIError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <docker.api.client.APIClient object at 0x7f6a9a2a3048>, response = <Response [403]>\n\n    def _raise_for_status(self, response):\n        \"\"\"Raises stored :class:`APIError`, if one occurred.\"\"\"\n        try:\n>           response.raise_for_status()\n\n../../../.local/share/virtualenvs/integration-testing-tsf_FPlY/lib/python3.6/site-packages/docker/api/client.py:261: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <Response [403]>\n\n    def raise_for_status(self):\n        \"\"\"Raises stored :class:`HTTPError`, if one occurred.\"\"\"\n    \n        http_error_msg = ''\n        if isinstance(self.reason, bytes):\n            # We attempt to decode utf-8 first because some servers\n            # choose to localize their reason strings. If the string\n            # isn't utf-8, we fall back to iso-8859-1 for all other\n            # encodings. (See PR #3538)\n            try:\n                reason = self.reason.decode('utf-8')\n            except UnicodeDecodeError:\n                reason = self.reason.decode('iso-8859-1')\n        else:\n            reason = self.reason\n    \n        if 400 <= self.status_code < 500:\n            http_error_msg = u'%s Client Error: %s for url: %s' % (self.status_code, reason, self.url)\n    \n        elif 500 <= self.status_code < 600:\n            http_error_msg = u'%s Server Error: %s for url: %s' % (self.status_code, reason, self.url)\n    \n        if http_error_msg:\n>           raise HTTPError(http_error_msg, response=self)\nE           requests.exceptions.HTTPError: 403 Client Error: Forbidden for url: http+docker://localhost/v1.35/networks/a6cb3773a0b7e747048d9f0393ef1028e4a89efb18e61936848c163517a9e5ce\n\n../../../.local/share/virtualenvs/integration-testing-tsf_FPlY/lib/python3.6/site-packages/requests/models.py:940: HTTPError\n\nDuring handling of the above exception, another exception occurred:\n\ncommand_line_options_fixture = CommandLineOptions(peer_count=2, node_startup_timeout=180, network_converge_timeout=220, receive_timeout=30, command_timeout=10, blocks=1, mount_dir=None)\ndocker_client_fixture = <docker.client.DockerClient object at 0x7f6a9a2a34e0>\n\n    def test_convergence(command_line_options_fixture, docker_client_fixture):\n        with conftest.testing_context(command_line_options_fixture, docker_client_fixture) as context:\n>           with complete_network(context) as network:\n\ntest_network_topology.py:72: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/lib/python3.6/contextlib.py:81: in __enter__\n    return next(self.gen)\ncl_node/casperlabsnode.py:784: in complete_network\n    with docker_network_with_started_bootstrap(context) as bootstrap_node:\n/usr/lib/python3.6/contextlib.py:81: in __enter__\n    return next(self.gen)\ncl_node/casperlabsnode.py:760: in docker_network_with_started_bootstrap\n    yield node\n/usr/lib/python3.6/contextlib.py:99: in __exit__\n    self.gen.throw(type, value, traceback)\ncl_node/casperlabsnode.py:711: in docker_network\n    network.remove()\n../../../.local/share/virtualenvs/integration-testing-tsf_FPlY/lib/python3.6/site-packages/docker/models/networks.py:89: in remove\n    return self.client.api.remove_network(self.id)\n../../../.local/share/virtualenvs/integration-testing-tsf_FPlY/lib/python3.6/site-packages/docker/utils/decorators.py:19: in wrapped\n    return f(self, resource_id, *args, **kwargs)\n../../../.local/share/virtualenvs/integration-testing-tsf_FPlY/lib/python3.6/site-packages/docker/api/network.py:186: in remove_network\n    self._raise_for_status(res)\n../../../.local/share/virtualenvs/integration-testing-tsf_FPlY/lib/python3.6/site-packages/docker/api/client.py:263: in _raise_for_status\n    raise create_api_error_from_http_exception(e)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ne = HTTPError('403 Client Error: Forbidden for url: http+docker://localhost/v1.35/networks/a6cb3773a0b7e747048d9f0393ef1028e4a89efb18e61936848c163517a9e5ce',)\n\n    def create_api_error_from_http_exception(e):\n        \"\"\"\n        Create a suitable APIError from requests.exceptions.HTTPError.\n        \"\"\"\n        response = e.response\n        try:\n            explanation = response.json()['message']\n        except ValueError:\n            explanation = (response.content or '').strip()\n        cls = APIError\n        if response.status_code == 404:\n            if explanation and ('No such image' in str(explanation) or\n                                'not found: does not exist or no pull access'\n                                in str(explanation) or\n                                'repository does not exist' in str(explanation)):\n                cls = ImageNotFound\n            else:\n                cls = NotFound\n>       raise cls(e, response=response, explanation=explanation)\nE       docker.errors.APIError: 403 Client Error: Forbidden (\"error while removing network: network casperlabsxxtxk id a6cb3773a0b7e747048d9f0393ef1028e4a89efb18e61936848c163517a9e5ce has active endpoints\")\n\n../../../.local/share/virtualenvs/integration-testing-tsf_FPlY/lib/python3.6/site-packages/docker/errors.py:31: APIError", "log": "INFO     root:casperlabsnode.py:303 bootstrap.casperlabsxxtxk command: run -s --server-host bootstrap.casperlabsxxtxk --tls-certificate /root/.casperlabs/bootstrap/node.certificate.pem --tls-key /root/.casperlabs/bootstrap/node.key.pem --casper-validator-private-key 901b1f0837b7e891d7c2ea0047f502fd95637e450b0226c39a97d68dd951c8a7 --casper-validator-public-key 00322ba649cebf90d8bd0eeb0658ea7957bcc59ecee0676c86f4fec517c06251 --grpc-socket /root/.casperlabs/sockets/.casper-node.sock --metrics-prometheus \nINFO     root:wait.py:206 AWAITING <NodeStarted('bootstrap.casperlabsxxtxk', 'io.casperlabs.node.NodeRuntime - Listening for traffic on casperlabs')>\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabsxxtxk: 10:31:13.565 [main] INFO  io.casperlabs.node.Main$ - CasperLabs node 0.3 (176160cd54206e3f9d599604b5e7a5e80e98f354)\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabsxxtxk: 10:31:13.572 [main] INFO  io.casperlabs.node.NodeEnvironment$ - Using data dir: /root/.casperlabs\nINFO     peers:casperlabsnode.py:268 \tbootstrap.casperlabsxxtxk: 10:31:13.796 [main] INFO  io.casperlabs.comm.UPnP$ - trying to open ports using UPnP...."}, "outcome": "failed"}}]}